{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocessing for torch\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "\n",
    "from dataset.data import MineData\n",
    "from models import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2840])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Load dataset\n",
    "mfcc_transform = torchaudio.transforms.MFCC(\n",
    "    sample_rate=48000, #36000 samples in 0.75s\n",
    "    n_mfcc=40, # 40 MFCC features\n",
    "    melkwargs={\n",
    "        \"n_fft\": 2048,\n",
    "        \"hop_length\": 512,\n",
    "        \"n_mels\": 128\n",
    "    }\n",
    ")\n",
    "\n",
    "data = MineData(\"./data/mine_impact_data_2019.mat\", transform = mfcc_transform)\n",
    "\n",
    "# Shuffle indices before splitting\n",
    "all_indices = list(range(len(data)))\n",
    "random.seed(42)  # for reproducibility\n",
    "random.shuffle(all_indices)\n",
    "\n",
    "# Split into train and test\n",
    "train_id = all_indices[:3000]\n",
    "test_id = all_indices[3000:]\n",
    "\n",
    "# Subset the data\n",
    "train_data = torch.utils.data.Subset(data, train_id)\n",
    "test_data = torch.utils.data.Subset(data, test_id)\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 1\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Class mapping\n",
    "class_map = {\n",
    "    0: \"drummy\",\n",
    "    1: \"tight\"\n",
    "}\n",
    "\n",
    "print(data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_train_var(model):\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "  return criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, batch_size):\n",
    "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "  model = models.Mine_MLP(nb_hidden=512)\n",
    "  model.to(device)\n",
    "  \n",
    "  criterion, optimizer = init_train_var(model=model)\n",
    "  history = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": []\n",
    "    }\n",
    "  train_steps = len(train_loader.dataset) // batch_size\n",
    "#   val_steps = len(val_loader.dataset) // batch_size\n",
    "\n",
    "  nb_epochs = 10\n",
    "  # run for nb_epochs\n",
    "  for e in range(nb_epochs):\n",
    "      # set the model in training mode\n",
    "      model.train()\n",
    "      # initialize the total training and validation loss\n",
    "      epoch_train_loss = 0\n",
    "    #   epoch_val_loss = 0\n",
    "      # initialize the number of correct predictions in the training\n",
    "      # and validation step\n",
    "      train_correct = 0\n",
    "    #   val_correct = 0\n",
    "\n",
    "      for x, y in train_loader:\n",
    "          \n",
    "          x, y = x.to(device), y.to(device)\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          pred = model(x)\n",
    "          loss = criterion(pred, y)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          # add the loss to the total training loss so far and\n",
    "          # calculate the number of correct predictions\n",
    "          epoch_train_loss += loss\n",
    "          train_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    #   # switch off autograd for validation\n",
    "    #   with torch.no_grad():\n",
    "    #       # set the model in evaluation mode\n",
    "    #       model.eval()\n",
    "    #       # loop over the validation set\n",
    "    #       for (x, y) in val_loader:\n",
    "\n",
    "    #           x, y = x.to(device), y.to(device)\n",
    "    #           pred = model(x)\n",
    "    #           loss = criterion(pred, y)\n",
    "    #           epoch_val_loss += loss\n",
    "    #           val_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "\n",
    "\n",
    "      # calculate the average epoch training and validation loss\n",
    "      mean_train_loss = epoch_train_loss / train_steps\n",
    "    #   mean_val_loss = epoch_val_loss / val_steps\n",
    "      # calculate the training and validation accuracy\n",
    "      train_correct = train_correct / len(train_loader.dataset)\n",
    "      # val_correct = val_correct / len(val_loader.dataset)\n",
    "      # update our training history\n",
    "      history[\"train_loss\"].append(mean_train_loss.cpu().detach().numpy())\n",
    "      history[\"train_acc\"].append(train_correct)\n",
    "    #   history[\"val_loss\"].append(mean_val_loss.cpu().detach().numpy())\n",
    "      # history[\"val_acc\"].append(val_correct)\n",
    "      # print the model training and validation information\n",
    "      print(\"[INFO] EPOCH: {}/{}\".format(e + 1, nb_epochs))\n",
    "      print(\"Train loss: {:.6f}, Train accuracy: {:.4f}\".format(\n",
    "          mean_train_loss, train_correct))\n",
    "    #   print(\"Val loss: {:.6f}, Val accuracy: {:.4f}\\n\".format(\n",
    "    #       mean_val_loss, val_correct))\n",
    "      # save the model if the validation loss is less than the previous\n",
    "      # if mean_val_loss - prev_mean_val_loss> 0.01:\n",
    "      #   break\n",
    "      # else:\n",
    "      #   prev_mean_val_loss = mean_val_loss\n",
    "\n",
    "  torch.save(model, \"models_mine_mlp.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model_path, test_loader):\n",
    "  # test on the test set\n",
    "  print(\"[INFO] Testing the model\")\n",
    "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "  model = torch.load(model_path,weights_only=False)\n",
    "  model.to(device)\n",
    "  test_correct = 0\n",
    "  with torch.no_grad():\n",
    "      model.eval()\n",
    "      for x, y in test_loader:\n",
    "          x, y = x.to(device), y.to(device)\n",
    "          pred = model(x)\n",
    "          test_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "  test_acc = test_correct / len(test_loader.dataset)\n",
    "  print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 1/10\n",
      "Train loss: 2.353846, Train accuracy: 0.8073\n",
      "[INFO] EPOCH: 2/10\n",
      "Train loss: 0.655482, Train accuracy: 0.8693\n",
      "[INFO] EPOCH: 3/10\n",
      "Train loss: 0.300817, Train accuracy: 0.8960\n",
      "[INFO] EPOCH: 4/10\n",
      "Train loss: 0.203368, Train accuracy: 0.9220\n",
      "[INFO] EPOCH: 5/10\n",
      "Train loss: 0.156575, Train accuracy: 0.9327\n",
      "[INFO] EPOCH: 6/10\n",
      "Train loss: 0.148086, Train accuracy: 0.9407\n",
      "[INFO] EPOCH: 7/10\n",
      "Train loss: 0.110861, Train accuracy: 0.9563\n",
      "[INFO] EPOCH: 8/10\n",
      "Train loss: 0.083687, Train accuracy: 0.9663\n",
      "[INFO] EPOCH: 9/10\n",
      "Train loss: 0.091012, Train accuracy: 0.9680\n",
      "[INFO] EPOCH: 10/10\n",
      "Train loss: 0.066700, Train accuracy: 0.9767\n"
     ]
    }
   ],
   "source": [
    "train(train_loader, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Testing the model\n",
      "Test accuracy: 0.9417\n"
     ]
    }
   ],
   "source": [
    "test(\"models_mine_mlp.pth\", test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
